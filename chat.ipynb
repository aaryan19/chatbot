{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdvlOaDF8Hc9",
        "outputId": "7e021326-ecbb-4ec3-d583-99db3a6508be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1k8usvpH6Ygh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qo4SM3k-YSU",
        "outputId": "e1451a29-71e0-4b3e-e26f-16a9d268ec88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "2XNSDnPe6m8V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents = json.loads(open('/content/drive/MyDrive/intents.json').read())"
      ],
      "metadata": {
        "id": "nmn3dDUi6rxA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_letters = ['?', ',', '.', '!', \"'\"]"
      ],
      "metadata": {
        "id": "DQfKD5rx6vpY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        word_list = nltk.word_tokenize(pattern)\n",
        "        words.extend(word_list)\n",
        "        documents.append((word_list, intent['tag']))\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ],
      "metadata": {
        "id": "znFllLBl8Q0A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWAQdZjA-lvk",
        "outputId": "a18c18d3-679f-440f-b55b-62f3f60ef83b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [lemmatizer.lemmatize(word) for word in words if word not in ignore_letters]\n",
        "words = sorted(set(words))"
      ],
      "metadata": {
        "id": "oTIUPP4O8T0y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = sorted(set(classes))"
      ],
      "metadata": {
        "id": "vh5TfH-V8Wfk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(words, open('words.pkl', 'wb'))\n",
        "pickle.dump(classes, open('classes.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "erFvw2i78aB5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = []\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "for document in documents:\n",
        "    bag = []\n",
        "    word_patterns = document[0]\n",
        "    word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
        "    for word in words:\n",
        "        bag.append(1) if word in word_patterns else bag.append(0)\n",
        "\n",
        "        output_row = list(output_empty)\n",
        "        output_row[classes.index(document[1])] = 1\n",
        "        training.append([bag, output_row])"
      ],
      "metadata": {
        "id": "WSJKiTib8duC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "train_x = list(training[:, 0])\n",
        "train_y = list(training[:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBEHwmxI8h1P",
        "outputId": "ec67663a-4b2f-412a-8eb1-a8517a76d54a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-b5d0b17a3307>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  training = np.array(training)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics='accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMcakLzw6lHh",
        "outputId": "9242c989-9414-4821-df72-75e6e3f20e61"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=300, batch_size=8, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8JS9xPZ8q3N",
        "outputId": "3d883d5c-5f8f-49f5-9289-f98413dfa36a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.9471 - accuracy: 0.7151\n",
            "Epoch 2/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.3166 - accuracy: 0.8862\n",
            "Epoch 3/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2626 - accuracy: 0.8995\n",
            "Epoch 4/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2416 - accuracy: 0.9014\n",
            "Epoch 5/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2312 - accuracy: 0.9054\n",
            "Epoch 6/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2251 - accuracy: 0.9055\n",
            "Epoch 7/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2197 - accuracy: 0.9042\n",
            "Epoch 8/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2180 - accuracy: 0.9063\n",
            "Epoch 9/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2155 - accuracy: 0.9073\n",
            "Epoch 10/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2128 - accuracy: 0.9079\n",
            "Epoch 11/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2116 - accuracy: 0.9090\n",
            "Epoch 12/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.2128 - accuracy: 0.9072\n",
            "Epoch 13/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2085 - accuracy: 0.9083\n",
            "Epoch 14/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2065 - accuracy: 0.9105\n",
            "Epoch 15/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2062 - accuracy: 0.9107\n",
            "Epoch 16/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2072 - accuracy: 0.9101\n",
            "Epoch 17/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2059 - accuracy: 0.9099\n",
            "Epoch 18/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2066 - accuracy: 0.9099\n",
            "Epoch 19/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2050 - accuracy: 0.9112\n",
            "Epoch 20/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2040 - accuracy: 0.9115\n",
            "Epoch 21/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2037 - accuracy: 0.9098\n",
            "Epoch 22/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2018 - accuracy: 0.9119\n",
            "Epoch 23/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2034 - accuracy: 0.9114\n",
            "Epoch 24/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2021 - accuracy: 0.9122\n",
            "Epoch 25/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2014 - accuracy: 0.9112\n",
            "Epoch 26/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2029 - accuracy: 0.9115\n",
            "Epoch 27/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2009 - accuracy: 0.9123\n",
            "Epoch 28/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2021 - accuracy: 0.9100\n",
            "Epoch 29/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2023 - accuracy: 0.9114\n",
            "Epoch 30/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2005 - accuracy: 0.9117\n",
            "Epoch 31/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2011 - accuracy: 0.9107\n",
            "Epoch 32/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1989 - accuracy: 0.9129\n",
            "Epoch 33/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1976 - accuracy: 0.9129\n",
            "Epoch 34/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2011 - accuracy: 0.9097\n",
            "Epoch 35/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1982 - accuracy: 0.9123\n",
            "Epoch 36/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1989 - accuracy: 0.9117\n",
            "Epoch 37/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1988 - accuracy: 0.9128\n",
            "Epoch 38/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1983 - accuracy: 0.9124\n",
            "Epoch 39/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1992 - accuracy: 0.9115\n",
            "Epoch 40/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1996 - accuracy: 0.9110\n",
            "Epoch 41/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1978 - accuracy: 0.9120\n",
            "Epoch 42/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1995 - accuracy: 0.9110\n",
            "Epoch 43/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1965 - accuracy: 0.9127\n",
            "Epoch 44/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1971 - accuracy: 0.9116\n",
            "Epoch 45/300\n",
            "2253/2253 [==============================] - 6s 2ms/step - loss: 0.1979 - accuracy: 0.9135\n",
            "Epoch 46/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1989 - accuracy: 0.9097\n",
            "Epoch 47/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1989 - accuracy: 0.9130\n",
            "Epoch 48/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2001 - accuracy: 0.9109\n",
            "Epoch 49/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1988 - accuracy: 0.9130\n",
            "Epoch 50/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1995 - accuracy: 0.9132\n",
            "Epoch 51/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1978 - accuracy: 0.9122\n",
            "Epoch 52/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1971 - accuracy: 0.9123\n",
            "Epoch 53/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1968 - accuracy: 0.9119\n",
            "Epoch 54/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1969 - accuracy: 0.9123\n",
            "Epoch 55/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1987 - accuracy: 0.9115\n",
            "Epoch 56/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1961 - accuracy: 0.9115\n",
            "Epoch 57/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1986 - accuracy: 0.9118\n",
            "Epoch 58/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1954 - accuracy: 0.9144\n",
            "Epoch 59/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1973 - accuracy: 0.9116\n",
            "Epoch 60/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1968 - accuracy: 0.9115\n",
            "Epoch 61/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1979 - accuracy: 0.9128\n",
            "Epoch 62/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1959 - accuracy: 0.9128\n",
            "Epoch 63/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1966 - accuracy: 0.9139\n",
            "Epoch 64/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1972 - accuracy: 0.9110\n",
            "Epoch 65/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1962 - accuracy: 0.9124\n",
            "Epoch 66/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1965 - accuracy: 0.9132\n",
            "Epoch 67/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1946 - accuracy: 0.9117\n",
            "Epoch 68/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1946 - accuracy: 0.9124\n",
            "Epoch 69/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1947 - accuracy: 0.9132\n",
            "Epoch 70/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1944 - accuracy: 0.9128\n",
            "Epoch 71/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1953 - accuracy: 0.9105\n",
            "Epoch 72/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1972 - accuracy: 0.9119\n",
            "Epoch 73/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1952 - accuracy: 0.9120\n",
            "Epoch 74/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1958 - accuracy: 0.9134\n",
            "Epoch 75/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1974 - accuracy: 0.9125\n",
            "Epoch 76/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1952 - accuracy: 0.9133\n",
            "Epoch 77/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1955 - accuracy: 0.9139\n",
            "Epoch 78/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1950 - accuracy: 0.9130\n",
            "Epoch 79/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1971 - accuracy: 0.9130\n",
            "Epoch 80/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1988 - accuracy: 0.9119\n",
            "Epoch 81/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1951 - accuracy: 0.9114\n",
            "Epoch 82/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1960 - accuracy: 0.9128\n",
            "Epoch 83/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1943 - accuracy: 0.9139\n",
            "Epoch 84/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1950 - accuracy: 0.9119\n",
            "Epoch 85/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1947 - accuracy: 0.9138\n",
            "Epoch 86/300\n",
            "2253/2253 [==============================] - 6s 3ms/step - loss: 0.1952 - accuracy: 0.9118\n",
            "Epoch 87/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1958 - accuracy: 0.9121\n",
            "Epoch 88/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1943 - accuracy: 0.9137\n",
            "Epoch 89/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1950 - accuracy: 0.9120\n",
            "Epoch 90/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1951 - accuracy: 0.9125\n",
            "Epoch 91/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1950 - accuracy: 0.9136\n",
            "Epoch 92/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1964 - accuracy: 0.9119\n",
            "Epoch 93/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1954 - accuracy: 0.9127\n",
            "Epoch 94/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1957 - accuracy: 0.9153\n",
            "Epoch 95/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1957 - accuracy: 0.9119\n",
            "Epoch 96/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1962 - accuracy: 0.9120\n",
            "Epoch 97/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1939 - accuracy: 0.9130\n",
            "Epoch 98/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1955 - accuracy: 0.9120\n",
            "Epoch 99/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1937 - accuracy: 0.9129\n",
            "Epoch 100/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1931 - accuracy: 0.9137\n",
            "Epoch 101/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1944 - accuracy: 0.9138\n",
            "Epoch 102/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1966 - accuracy: 0.9122\n",
            "Epoch 103/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1940 - accuracy: 0.9135\n",
            "Epoch 104/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1938 - accuracy: 0.9145\n",
            "Epoch 105/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1945 - accuracy: 0.9129\n",
            "Epoch 106/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1940 - accuracy: 0.9125\n",
            "Epoch 107/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1962 - accuracy: 0.9128\n",
            "Epoch 108/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1932 - accuracy: 0.9137\n",
            "Epoch 109/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1942 - accuracy: 0.9118\n",
            "Epoch 110/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1956 - accuracy: 0.9110\n",
            "Epoch 111/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1935 - accuracy: 0.9138\n",
            "Epoch 112/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1927 - accuracy: 0.9144\n",
            "Epoch 113/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1942 - accuracy: 0.9138\n",
            "Epoch 114/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1939 - accuracy: 0.9137\n",
            "Epoch 115/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9140\n",
            "Epoch 116/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1937 - accuracy: 0.9139\n",
            "Epoch 117/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1940 - accuracy: 0.9138\n",
            "Epoch 118/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1944 - accuracy: 0.9143\n",
            "Epoch 119/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1939 - accuracy: 0.9133\n",
            "Epoch 120/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1940 - accuracy: 0.9144\n",
            "Epoch 121/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1939 - accuracy: 0.9132\n",
            "Epoch 122/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1925 - accuracy: 0.9137\n",
            "Epoch 123/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1932 - accuracy: 0.9131\n",
            "Epoch 124/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1947 - accuracy: 0.9125\n",
            "Epoch 125/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1932 - accuracy: 0.9143\n",
            "Epoch 126/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1945 - accuracy: 0.9121\n",
            "Epoch 127/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1935 - accuracy: 0.9121\n",
            "Epoch 128/300\n",
            "2253/2253 [==============================] - 6s 3ms/step - loss: 0.1945 - accuracy: 0.9122\n",
            "Epoch 129/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1955 - accuracy: 0.9121\n",
            "Epoch 130/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1935 - accuracy: 0.9141\n",
            "Epoch 131/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1927 - accuracy: 0.9126\n",
            "Epoch 132/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1967 - accuracy: 0.9128\n",
            "Epoch 133/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9138\n",
            "Epoch 134/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1952 - accuracy: 0.9106\n",
            "Epoch 135/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9138\n",
            "Epoch 136/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9140\n",
            "Epoch 137/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1938 - accuracy: 0.9132\n",
            "Epoch 138/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1937 - accuracy: 0.9130\n",
            "Epoch 139/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1946 - accuracy: 0.9116\n",
            "Epoch 140/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1948 - accuracy: 0.9123\n",
            "Epoch 141/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1939 - accuracy: 0.9123\n",
            "Epoch 142/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1930 - accuracy: 0.9124\n",
            "Epoch 143/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9125\n",
            "Epoch 144/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1931 - accuracy: 0.9140\n",
            "Epoch 145/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1935 - accuracy: 0.9142\n",
            "Epoch 146/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1925 - accuracy: 0.9138\n",
            "Epoch 147/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1947 - accuracy: 0.9133\n",
            "Epoch 148/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9135\n",
            "Epoch 149/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1940 - accuracy: 0.9137\n",
            "Epoch 150/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1937 - accuracy: 0.9128\n",
            "Epoch 151/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1940 - accuracy: 0.9134\n",
            "Epoch 152/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1915 - accuracy: 0.9145\n",
            "Epoch 153/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1922 - accuracy: 0.9141\n",
            "Epoch 154/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1947 - accuracy: 0.9134\n",
            "Epoch 155/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9138\n",
            "Epoch 156/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1938 - accuracy: 0.9125\n",
            "Epoch 157/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1926 - accuracy: 0.9135\n",
            "Epoch 158/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1923 - accuracy: 0.9133\n",
            "Epoch 159/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1918 - accuracy: 0.9141\n",
            "Epoch 160/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1934 - accuracy: 0.9131\n",
            "Epoch 161/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1932 - accuracy: 0.9132\n",
            "Epoch 162/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1913 - accuracy: 0.9131\n",
            "Epoch 163/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1942 - accuracy: 0.9121\n",
            "Epoch 164/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1944 - accuracy: 0.9136\n",
            "Epoch 165/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1922 - accuracy: 0.9134\n",
            "Epoch 166/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1934 - accuracy: 0.9119\n",
            "Epoch 167/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1931 - accuracy: 0.9130\n",
            "Epoch 168/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1930 - accuracy: 0.9135\n",
            "Epoch 169/300\n",
            "2253/2253 [==============================] - 7s 3ms/step - loss: 0.1927 - accuracy: 0.9135\n",
            "Epoch 170/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1937 - accuracy: 0.9133\n",
            "Epoch 171/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1924 - accuracy: 0.9147\n",
            "Epoch 172/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1934 - accuracy: 0.9133\n",
            "Epoch 173/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1924 - accuracy: 0.9142\n",
            "Epoch 174/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9128\n",
            "Epoch 175/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1926 - accuracy: 0.9141\n",
            "Epoch 176/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1931 - accuracy: 0.9135\n",
            "Epoch 177/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1917 - accuracy: 0.9136\n",
            "Epoch 178/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9148\n",
            "Epoch 179/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1925 - accuracy: 0.9133\n",
            "Epoch 180/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1909 - accuracy: 0.9132\n",
            "Epoch 181/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1903 - accuracy: 0.9137\n",
            "Epoch 182/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9144\n",
            "Epoch 183/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1910 - accuracy: 0.9144\n",
            "Epoch 184/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1926 - accuracy: 0.9137\n",
            "Epoch 185/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1925 - accuracy: 0.9137\n",
            "Epoch 186/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9133\n",
            "Epoch 187/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9132\n",
            "Epoch 188/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1925 - accuracy: 0.9140\n",
            "Epoch 189/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1924 - accuracy: 0.9128\n",
            "Epoch 190/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1919 - accuracy: 0.9133\n",
            "Epoch 191/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1927 - accuracy: 0.9129\n",
            "Epoch 192/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1918 - accuracy: 0.9148\n",
            "Epoch 193/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1936 - accuracy: 0.9139\n",
            "Epoch 194/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9132\n",
            "Epoch 195/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1920 - accuracy: 0.9133\n",
            "Epoch 196/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1918 - accuracy: 0.9142\n",
            "Epoch 197/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1923 - accuracy: 0.9122\n",
            "Epoch 198/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1918 - accuracy: 0.9144\n",
            "Epoch 199/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1927 - accuracy: 0.9113\n",
            "Epoch 200/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1914 - accuracy: 0.9140\n",
            "Epoch 201/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1932 - accuracy: 0.9139\n",
            "Epoch 202/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1935 - accuracy: 0.9141\n",
            "Epoch 203/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1915 - accuracy: 0.9135\n",
            "Epoch 204/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1901 - accuracy: 0.9149\n",
            "Epoch 205/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9149\n",
            "Epoch 206/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1913 - accuracy: 0.9132\n",
            "Epoch 207/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1921 - accuracy: 0.9131\n",
            "Epoch 208/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1931 - accuracy: 0.9144\n",
            "Epoch 209/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1934 - accuracy: 0.9130\n",
            "Epoch 210/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1915 - accuracy: 0.9147\n",
            "Epoch 211/300\n",
            "2253/2253 [==============================] - 6s 2ms/step - loss: 0.1930 - accuracy: 0.9134\n",
            "Epoch 212/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1920 - accuracy: 0.9137\n",
            "Epoch 213/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1910 - accuracy: 0.9137\n",
            "Epoch 214/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1921 - accuracy: 0.9126\n",
            "Epoch 215/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1925 - accuracy: 0.9128\n",
            "Epoch 216/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1930 - accuracy: 0.9126\n",
            "Epoch 217/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1926 - accuracy: 0.9134\n",
            "Epoch 218/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1925 - accuracy: 0.9134\n",
            "Epoch 219/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1921 - accuracy: 0.9151\n",
            "Epoch 220/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1912 - accuracy: 0.9149\n",
            "Epoch 221/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1932 - accuracy: 0.9128\n",
            "Epoch 222/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1920 - accuracy: 0.9120\n",
            "Epoch 223/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1916 - accuracy: 0.9127\n",
            "Epoch 224/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1931 - accuracy: 0.9123\n",
            "Epoch 225/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1915 - accuracy: 0.9130\n",
            "Epoch 226/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1907 - accuracy: 0.9139\n",
            "Epoch 227/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1939 - accuracy: 0.9139\n",
            "Epoch 228/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9123\n",
            "Epoch 229/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1921 - accuracy: 0.9147\n",
            "Epoch 230/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1918 - accuracy: 0.9130\n",
            "Epoch 231/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1916 - accuracy: 0.9145\n",
            "Epoch 232/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1919 - accuracy: 0.9127\n",
            "Epoch 233/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1918 - accuracy: 0.9131\n",
            "Epoch 234/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9120\n",
            "Epoch 235/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1935 - accuracy: 0.9128\n",
            "Epoch 236/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1906 - accuracy: 0.9151\n",
            "Epoch 237/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1916 - accuracy: 0.9146\n",
            "Epoch 238/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1919 - accuracy: 0.9122\n",
            "Epoch 239/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1919 - accuracy: 0.9128\n",
            "Epoch 240/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1905 - accuracy: 0.9137\n",
            "Epoch 241/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1920 - accuracy: 0.9134\n",
            "Epoch 242/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1911 - accuracy: 0.9137\n",
            "Epoch 243/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1918 - accuracy: 0.9143\n",
            "Epoch 244/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1907 - accuracy: 0.9153\n",
            "Epoch 245/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1917 - accuracy: 0.9138\n",
            "Epoch 246/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1920 - accuracy: 0.9138\n",
            "Epoch 247/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1920 - accuracy: 0.9139\n",
            "Epoch 248/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1920 - accuracy: 0.9130\n",
            "Epoch 249/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1916 - accuracy: 0.9135\n",
            "Epoch 250/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1927 - accuracy: 0.9140\n",
            "Epoch 251/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1913 - accuracy: 0.9145\n",
            "Epoch 252/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1911 - accuracy: 0.9129\n",
            "Epoch 253/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1924 - accuracy: 0.9135\n",
            "Epoch 254/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1925 - accuracy: 0.9135\n",
            "Epoch 255/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1930 - accuracy: 0.9138\n",
            "Epoch 256/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1909 - accuracy: 0.9140\n",
            "Epoch 257/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9146\n",
            "Epoch 258/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1915 - accuracy: 0.9144\n",
            "Epoch 259/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1921 - accuracy: 0.9130\n",
            "Epoch 260/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1918 - accuracy: 0.9139\n",
            "Epoch 261/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1922 - accuracy: 0.9145\n",
            "Epoch 262/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1921 - accuracy: 0.9142\n",
            "Epoch 263/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1913 - accuracy: 0.9144\n",
            "Epoch 264/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1918 - accuracy: 0.9145\n",
            "Epoch 265/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1915 - accuracy: 0.9144\n",
            "Epoch 266/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9140\n",
            "Epoch 267/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1911 - accuracy: 0.9137\n",
            "Epoch 268/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1930 - accuracy: 0.9135\n",
            "Epoch 269/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1920 - accuracy: 0.9144\n",
            "Epoch 270/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1912 - accuracy: 0.9133\n",
            "Epoch 271/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1912 - accuracy: 0.9133\n",
            "Epoch 272/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1919 - accuracy: 0.9137\n",
            "Epoch 273/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1909 - accuracy: 0.9117\n",
            "Epoch 274/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1905 - accuracy: 0.9150\n",
            "Epoch 275/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1916 - accuracy: 0.9125\n",
            "Epoch 276/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1936 - accuracy: 0.9124\n",
            "Epoch 277/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1906 - accuracy: 0.9140\n",
            "Epoch 278/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1910 - accuracy: 0.9147\n",
            "Epoch 279/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1917 - accuracy: 0.9129\n",
            "Epoch 280/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1923 - accuracy: 0.9153\n",
            "Epoch 281/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1919 - accuracy: 0.9132\n",
            "Epoch 282/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1918 - accuracy: 0.9139\n",
            "Epoch 283/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1909 - accuracy: 0.9135\n",
            "Epoch 284/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1910 - accuracy: 0.9151\n",
            "Epoch 285/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1905 - accuracy: 0.9163\n",
            "Epoch 286/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1912 - accuracy: 0.9152\n",
            "Epoch 287/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1918 - accuracy: 0.9130\n",
            "Epoch 288/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1925 - accuracy: 0.9128\n",
            "Epoch 289/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1918 - accuracy: 0.9132\n",
            "Epoch 290/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1916 - accuracy: 0.9137\n",
            "Epoch 291/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1910 - accuracy: 0.9132\n",
            "Epoch 292/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1916 - accuracy: 0.9147\n",
            "Epoch 293/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1903 - accuracy: 0.9139\n",
            "Epoch 294/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1914 - accuracy: 0.9122\n",
            "Epoch 295/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1917 - accuracy: 0.9133\n",
            "Epoch 296/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1918 - accuracy: 0.9142\n",
            "Epoch 297/300\n",
            "2253/2253 [==============================] - 6s 2ms/step - loss: 0.1905 - accuracy: 0.9135\n",
            "Epoch 298/300\n",
            "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1907 - accuracy: 0.9137\n",
            "Epoch 299/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1907 - accuracy: 0.9136\n",
            "Epoch 300/300\n",
            "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1916 - accuracy: 0.9137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('chatbotmodel.h5', hist)\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3RQSdRT8m8i",
        "outputId": "dbb5430d-b1ed-40ca-9441-8748ad1055a8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "xICda9rI-86x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = pickle.load(open('words.pkl', 'rb'))\n",
        "classes = pickle.load(open('classes.pkl','rb'))\n",
        "model = load_model('chatbotmodel.h5')"
      ],
      "metadata": {
        "id": "X-ntq5e9_wZG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_up_sentence(sentence):\n",
        "  sentence_words = nltk.word_tokenize(sentence)\n",
        "  sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n",
        "  return sentence_words"
      ],
      "metadata": {
        "id": "mmsW34_jAfhw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bag_of_words(sentence):\n",
        "  sentence_words = clean_up_sentence(sentence)\n",
        "  bag = [0] * len(words)\n",
        "  for w in sentence_words:\n",
        "    for i, word in enumerate(words):\n",
        "      if word == w:\n",
        "        bag[i] = 1\n",
        "  return np.array(bag)"
      ],
      "metadata": {
        "id": "sBvwJZ80BCJH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_class(sentence):\n",
        "  bow = bag_of_words(sentence)\n",
        "  res = model.predict(np.array([bow]))[0]\n",
        "  ERROR_THRESHOLD = 0.25\n",
        "  results = [[i,r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "\n",
        "  results.sort(key=lambda x: x[1], reverse=True)\n",
        "  return_list = []\n",
        "  for r in results:\n",
        "    return_list.append({'intent': classes[r[0]], 'probability': str(r[1])})\n",
        "  return return_list"
      ],
      "metadata": {
        "id": "KR2vXeOZBiv0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(intents_list, intents_json):\n",
        "  tag = intents_list[0]['intent']\n",
        "  list_of_intents = intents_json['intents']\n",
        "  for i in list_of_intents:\n",
        "    if i['tag'] == tag:\n",
        "      result = random.choice(i['responses'])\n",
        "      break\n",
        "  return result"
      ],
      "metadata": {
        "id": "YZwZP9T_DhS3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Go\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PorvZgOLEZ-V",
        "outputId": "5a4d3bff-f40c-40da-8675-36033e68fa4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  message = input(\"\")\n",
        "  ints = predict_class(message)\n",
        "  res = get_response(ints, intents)\n",
        "  print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_tImiyIsQqM-",
        "outputId": "3e75b151-0ac7-4182-c9ea-994917ac2e1a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "good morning\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "What's going on?\n",
            "nothing much. eating food\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "I like to eat chips...\n",
            "do you like other things?\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Texas Chainsaw Massacre is my favorite horror movie of all time\n",
            "why?\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Goodbye\n",
            "wait. do you watch anime?\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Burt Kreischer\n",
            "i am confused\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Peace\n",
            "tell me about crypto or data science\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured and unstructured data\n",
            "where did you study?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Acting\n",
            "where?\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Preserving oxygen\n",
            "wait what?\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "I don't know\n",
            "okay. what is your name?\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Bots don't get married they get compiled\n",
            "that is funny\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Only when people hurt others\n",
            "ok bye\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Nice talking to you\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c6b8ca17239c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "2-8gbfbmQ973"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}